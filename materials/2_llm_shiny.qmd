---
execute:
  echo: true
format:
  revealjs: 
    theme: default
engine: knitr
editor: source
---

# Creating LLM-Powered Shiny Apps {#llmshiny}

<!-- 1h 45 mins teaching time maximum -->

## Learning Outcomes

Participants will understand how to:
- How to structure Shiny apps with {ellmer} components, referencing the provided template
- How to implement basic input validation to mitigate prompt injection risks
- How to get structured outputs from it
- Best practices for reactivity so not making too many requests

## Shiny app basics and where {ellmer} should be integrated 

(as app not package for simplicity)

## Storing prompts in inst and using glue-like syntax

# UX

## Input validation

* Free text == dangerous + examples of past hacks from books

## Output sanitisation

* e.g. limit length, working with structured output

## Abuse potential

## Waiting for output

* i.e. use spinners, disable button while submitting

## Display errors gracefully

* trycatch or whatever

## Retrieving structured output

## Demo
- Walkthrough of the provided Shiny app skeleton:
- Review UI and server structure.
- Identify where {ellmer} should be integrated and prompts stored

# Guardrails

## Cost Control - Limiting usage with Gemini

## Cost Control - Usage Monitoring

## Limiting token usage via reactivity (button press) and monitoring usage 

## Preventing too many calls within short space of time (button reclick?)

## Observability - use basic logging for requests

## Exercise: Creating own prompt templates in the app and Adding input validation for free text fields
